#!/usr/bin/env python3
"""
æµ‹è¯•build_vis_cache.pyçš„åŠŸèƒ½
"""
import os
import sys
import tempfile
import shutil
from pathlib import Path
import numpy as np
import torch
from PIL import Image
import argparse

# æ·»åŠ eomtè·¯å¾„
# sys.path.append("eomt")

# æµ‹è¯•å¯¼å…¥
try:
    from eomt.datasets.build_vis_cache import (
        create_dataloader, 
        extract_image_and_segment_ids,
        prep_mask_image,
        save_image_embeddings
    )
    print("âœ… æˆåŠŸå¯¼å…¥build_vis_cacheæ¨¡å—")
except ImportError as e:
    print(f"âŒ å¯¼å…¥build_vis_cacheæ¨¡å—å¤±è´¥: {e}")
    sys.exit(1)

# æµ‹è¯•novic embedderså¯¼å…¥
try:
    sys.path.append("novic")
    from eomt.novic.embedders import Embedder
    print("âœ… æˆåŠŸå¯¼å…¥novic embedders")
    NOVIC_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ novic embedderså¯¼å…¥å¤±è´¥: {e}")
    print("å°†è·³è¿‡éœ€è¦novicçš„æµ‹è¯•")
    NOVIC_AVAILABLE = False


def create_dummy_image_data():
    """åˆ›å»ºè™šæ‹Ÿçš„å›¾åƒå’Œmaskæ•°æ®ç”¨äºæµ‹è¯•"""
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„RGBå›¾åƒ [3, 64, 64]
    image = torch.rand(3, 64, 64)
    
    # åˆ›å»ºå‡ ä¸ªè™šæ‹Ÿçš„masks [H, W]
    mask1 = torch.zeros(64, 64, dtype=torch.bool)
    mask1[10:30, 10:30] = True  # ç¬¬ä¸€ä¸ªmaskåŒºåŸŸ
    
    mask2 = torch.zeros(64, 64, dtype=torch.bool) 
    mask2[40:60, 40:60] = True  # ç¬¬äºŒä¸ªmaskåŒºåŸŸ
    
    masks = [mask1, mask2]
    labels = [1, 2]  # ç±»åˆ«æ ‡ç­¾
    target_ids = [12345, 67890]  # segment IDs
    
    return image, masks, labels, target_ids

import matplotlib.pyplot as plt
import cv2
from matplotlib.colors import ListedColormap

def visualize_extracted_segments(image_tensor, masks, target_ids, labels, image_id, save_dir=None):
    """
    å¯è§†åŒ–æå–çš„å›¾åƒå’Œsegment masksï¼Œå¹¶åœ¨æ¯ä¸ªmaskä¸Šæ˜¾ç¤ºå¯¹åº”çš„ID
    
    Args:
        image_tensor: å›¾åƒå¼ é‡ (C, H, W)
        masks: maskå¼ é‡ (N, H, W) 
        target_ids: segment IDåˆ—è¡¨
        labels: æ ‡ç­¾åˆ—è¡¨
        image_id: å›¾åƒID
        save_dir: ä¿å­˜ç›®å½•ï¼ˆå¯é€‰ï¼‰
    """
    print(f"\nğŸ¨ å¯è§†åŒ–å›¾åƒ {image_id} çš„segmentæå–ç»“æœ...")
    
    # åˆ›å»ºå›¾åƒ
    fig, axes = plt.subplots(1, 3, figsize=[21, 7])
    
    # 1. æ˜¾ç¤ºåŸå§‹å›¾åƒ
    if isinstance(image_tensor, torch.Tensor):
        img_np = image_tensor.cpu().numpy()
    else:
        img_np = image_tensor
    
    # è½¬æ¢å›¾åƒæ ¼å¼ (C, H, W) -> (H, W, C)
    if img_np.shape[0] in [1, 3]:  # é€šé“åœ¨ç¬¬ä¸€ç»´
        img_np = img_np.transpose(1, 2, 0)
    
    # å½’ä¸€åŒ–åˆ°0-255
    if img_np.max() <= 1.0:
        img_np = (img_np * 255).astype(np.uint8)
    
    # å¦‚æœæ˜¯å•é€šé“ï¼Œè½¬æ¢ä¸ºRGB
    if img_np.shape[-1] == 1:
        img_np = np.repeat(img_np, 3, axis=-1)
    elif img_np.shape[-1] > 3:
        img_np = img_np[:, :, :3]
    
    axes[0].imshow(img_np)
    axes[0].set_title(f"Original Image - {image_id}", fontsize=14)
    axes[0].axis("off")
    
    # 2. åˆ›å»ºå½©è‰²çš„segmentå¯è§†åŒ–
    H, W = img_np.shape[:2]
    segment_viz = np.zeros((H, W, 3), dtype=np.uint8)
    
    # è®¾ç½®éšæœºç§å­ä»¥è·å¾—ä¸€è‡´çš„é¢œè‰²
    np.random.seed(42)
    
    # ä¸ºæ¯ä¸ªsegmentåˆ†é…é¢œè‰²å¹¶ç»˜åˆ¶
    colors_used = []
    for i, (mask, seg_id, label) in enumerate(zip(masks, target_ids, labels)):
        if isinstance(mask, torch.Tensor):
            mask_np = mask.cpu().numpy().astype(bool)
        else:
            mask_np = mask.astype(bool)
        
        if mask_np.sum() == 0:  # è·³è¿‡ç©ºmask
            continue
        
        # ç”Ÿæˆéšæœºé¢œè‰²
        color = (np.random.rand(3) * 200 + 55).astype(np.uint8)  # é¿å…å¤ªæš—çš„é¢œè‰²
        colors_used.append(color)
        
        # åº”ç”¨é¢œè‰²åˆ°maskåŒºåŸŸ
        segment_viz[mask_np] = color
    
    axes[1].imshow(segment_viz)
    axes[1].set_title(f"Colored Segments (Total: {len(target_ids)})", fontsize=14)
    axes[1].axis("off")
    
    # 3. åˆ›å»ºå¸¦IDæ ‡æ³¨çš„å¯è§†åŒ–
    segment_with_ids = segment_viz.copy()
    
    # ä¸ºæ¯ä¸ªsegmentæ·»åŠ IDæ ‡æ³¨
    for i, (mask, seg_id, label) in enumerate(zip(masks, target_ids, labels)):
        if isinstance(mask, torch.Tensor):
            mask_np = mask.cpu().numpy().astype(bool)
        else:
            mask_np = mask.astype(bool)
        
        if mask_np.sum() == 0:
            continue
        
        # æ‰¾åˆ°maskçš„ä¸­å¿ƒç‚¹
        y_coords, x_coords = np.where(mask_np)
        if len(y_coords) > 0:
            center_y = int(np.mean(y_coords))
            center_x = int(np.mean(x_coords))
            
            # åœ¨ä¸­å¿ƒç‚¹æ·»åŠ æ–‡æœ¬æ ‡æ³¨
            text = f"ID:{seg_id}\nL:{label}"
            
            # æ·»åŠ ç™½è‰²èƒŒæ™¯çš„æ–‡æœ¬
            cv2.putText(segment_with_ids, f"ID:{seg_id}", 
                       (center_x-20, center_y-5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
            cv2.putText(segment_with_ids, f"ID:{seg_id}", 
                       (center_x-20, center_y-5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)
            
            cv2.putText(segment_with_ids, f"L:{label}", 
                       (center_x-15, center_y+15), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 2)
            cv2.putText(segment_with_ids, f"L:{label}", 
                       (center_x-15, center_y+15), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1)
    
    axes[2].imshow(segment_with_ids)
    axes[2].set_title(f"Segments with IDs", fontsize=14)
    axes[2].axis("off")
    
    # æ·»åŠ è¯¦ç»†ä¿¡æ¯
    info_text = f"Image ID: {image_id}\n"
    info_text += f"Image Shape: {img_np.shape}\n"
    info_text += f"Segments Count: {len(target_ids)}\n"
    info_text += f"Segment IDs: {target_ids[:8]}{'...' if len(target_ids) > 8 else ''}\n"
    info_text += f"Labels: {labels[:8]}{'...' if len(labels) > 8 else ''}"
    
    fig.suptitle(info_text, fontsize=12, y=0.02, ha='left', va='bottom')
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾åƒ
    if save_dir:
        from pathlib import Path
        save_dir = Path(save_dir)
        save_dir.mkdir(exist_ok=True)
        save_path = save_dir / f"segment_visualization_{image_id}.png"
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"   å¯è§†åŒ–å›¾åƒå·²ä¿å­˜åˆ°: {save_path}")
    
    # æ˜¾ç¤ºå›¾åƒ
    plt.show()
    plt.close()
    
    # æ‰“å°è¯¦ç»†çš„segmentä¿¡æ¯
    print(f"\nğŸ“‹ è¯¦ç»†segmentä¿¡æ¯:")
    for i, (mask, seg_id, label) in enumerate(zip(masks, target_ids, labels)):
        if isinstance(mask, torch.Tensor):
            pixel_count = mask.sum().item()
        else:
            pixel_count = mask.sum()
        
        percentage = (pixel_count / (H * W)) * 100
        print(f"   Segment {i+1:2d}: ID={seg_id:>6}, Label={label:>3}, "
              f"Pixels={pixel_count:>6} ({percentage:>5.2f}%)")


def test_real_dataset(data_path: str, output_dir: str = None):
    """æµ‹è¯•çœŸå®COCOæ•°æ®é›†çš„å•ä¸ªå›¾åƒå¤„ç†"""
    print(f"\nğŸ”„ æµ‹è¯•çœŸå®æ•°æ®é›†å¤„ç†...")
    print(f"æ•°æ®è·¯å¾„: {data_path}")
    
    if not Path(data_path).exists():
        print(f"âš ï¸ æ•°æ®è·¯å¾„ä¸å­˜åœ¨ï¼Œè·³è¿‡çœŸå®æ•°æ®é›†æµ‹è¯•: {data_path}")
        return True
    
    if not NOVIC_AVAILABLE:
        print("âš ï¸ novicä¸å¯ç”¨ï¼Œè·³è¿‡çœŸå®æ•°æ®é›†æµ‹è¯•")
        return True
    
    try:
        # åˆ›å»ºè¾“å‡ºç›®å½•
        if output_dir is None:
            temp_dir = Path(tempfile.mkdtemp())
            cleanup_temp = True
        else:
            temp_dir = Path(output_dir)
            temp_dir.mkdir(parents=True, exist_ok=True)
            cleanup_temp = False
        
        print(f"è¾“å‡ºç›®å½•: {temp_dir}")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆåªå¤„ç†å°‘é‡æ•°æ®ï¼‰
        print("åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
        dataloader = create_dataloader(
            data_path=data_path,
            batch_size=1,  # ä¸€æ¬¡åªå¤„ç†ä¸€ä¸ªå›¾åƒ
            num_workers=0
        )
        

        # åˆ›å»ºSigLIPåµŒå…¥å™¨
        print("åŠ è½½SigLIPæ¨¡å‹...")
        import os
        os.environ['HF_HOME'] = '/home/host_ssd/huggingface'
        os.environ['TRANSFORMERS_CACHE'] = '/home/host_ssd/huggingface'
        embedder = Embedder.create(
            spec="openclip:timm/ViT-B-16-SigLIP",
            # spec = "openclip:file:///home/host_ssd/huggingface/ViT-B-16-SigLIP",
            # spec = "/home/host_ssd/huggingface/ViT-B-16-SigLIP",
            amp=True,
            device="cuda",  
            inference_batch_size=32,
            image_batch_size=16,
            load_model=True,
            compile_model=False,
        )
        
        # è·å–å›¾åƒé¢„å¤„ç†å‡½æ•°
        image_transform = embedder.get_image_transform()
        
        # å¤„ç†ç¬¬ä¸€ä¸ªæ‰¹æ¬¡
        print("å¤„ç†ç¬¬ä¸€ä¸ªæ‰¹æ¬¡...")
        batch_iter = iter(dataloader)
        batch = next(batch_iter)
        
        # æå–æ‰¹æ¬¡ä¿¡æ¯
        batch_info = extract_image_and_segment_ids(batch, dataloader)
        
        if not batch_info:
            print("âŒ æœªèƒ½ä»æ•°æ®åŠ è½½å™¨æå–æœ‰æ•ˆæ•°æ®")
            return False
        
        # å¤„ç†ç¬¬ä¸€ä¸ªå›¾åƒ
        image_id, image_tensor, masks, labels, target_ids = batch_info[0]
        
        print(f"å¤„ç†å›¾åƒ: {image_id}")
        print(f"  - å›¾åƒå°ºå¯¸: {image_tensor.shape}")
        print(f"  - Maskæ•°é‡: {len(masks)}")
        print(f"  - Segment IDs: {target_ids[:5]}{'...' if len(target_ids) > 5 else ''}")

        # ğŸ¨ æ·»åŠ å¯è§†åŒ–
        visualize_extracted_segments(
            image_tensor=image_tensor,
            masks=masks, 
            target_ids=target_ids,
            labels=labels,
            image_id=image_id,
            save_dir="./"  # å¯ä»¥ä¿®æ”¹ä¿å­˜è·¯å¾„
        )

        if not masks or not target_ids:
            print("âŒ å›¾åƒæ²¡æœ‰æœ‰æ•ˆçš„maskæˆ–target_ids")
            return False
        
        # ä¸ºæ‰€æœ‰maskå‡†å¤‡å›¾åƒ
        print("é¢„å¤„ç†maskå›¾åƒ...")
        processed_images, valid_indices, valid_segment_ids, valid_labels = prep_mask_image(
            image_tensor, masks, labels, target_ids,
            bg_alpha=0.3, pad_ratio=0.1
        )
        
        if not processed_images:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„å¤„ç†åå›¾åƒ")
            return False
        
        print(f"æˆåŠŸé¢„å¤„ç† {len(processed_images)} ä¸ªmaskå›¾åƒ")
        
        # æ‰¹é‡å¤„ç†å›¾åƒ
        print("è½¬æ¢å›¾åƒæ ¼å¼...")
        image_tensors = []
        for pil_img in processed_images:
            tensor = image_transform(pil_img)
            image_tensors.append(tensor)
        
        if image_tensors:
            # æ‰¹é‡æ¨ç†
            print("æ‰§è¡ŒSigLIPæ¨ç†...")
            batch_tensor = torch.stack(image_tensors)
            
            with embedder.inference_mode():
                embeddings = embedder.inference_image(batch_tensor)
            
            print(f"ç”Ÿæˆ {len(embeddings)} ä¸ªåµŒå…¥å‘é‡ï¼Œæ¯ä¸ªç»´åº¦: {embeddings[0].shape}")
            
            # ä¿å­˜è¯¥å›¾åƒçš„æ‰€æœ‰embeddings
            print("ä¿å­˜åµŒå…¥å‘é‡...")
            success = save_image_embeddings(
                temp_dir, image_id, valid_segment_ids, 
                embeddings, valid_labels
            )
            
            if success:
                # éªŒè¯ä¿å­˜çš„æ–‡ä»¶
                npz_file = temp_dir / f"{image_id}.npz"
                data = np.load(npz_file)
                
                print(f"âœ… çœŸå®æ•°æ®é›†æµ‹è¯•æˆåŠŸï¼")
                print(f"   - å›¾åƒID: {image_id}")
                print(f"   - ä¿å­˜æ–‡ä»¶: {npz_file}")
                print(f"   - Segmentæ•°é‡: {len(data['segment_ids'])}")
                print(f"   - åµŒå…¥å½¢çŠ¶: {data['embeddings'].shape}")
                print(f"   - æ•°æ®ç±»å‹: {data['embeddings'].dtype}")
                print(f"   - Segment IDsç¤ºä¾‹: {data['segment_ids'][:5]}")
                print(f"   - Labelsç¤ºä¾‹: {data['labels'][:5]}")
                
                # æ˜¾ç¤ºä¸€äº›ç»Ÿè®¡ä¿¡æ¯
                print(f"   - åµŒå…¥å‘é‡èŒƒå›´: [{data['embeddings'].min():.3f}, {data['embeddings'].max():.3f}]")
                print(f"   - åµŒå…¥å‘é‡å‡å€¼: {data['embeddings'].mean():.3f}")
                print(f"   - åµŒå…¥å‘é‡æ ‡å‡†å·®: {data['embeddings'].std():.3f}")
                
                # åˆ›å»ºç´¢å¼•æ–‡ä»¶
                index_file = temp_dir / "image_index.tsv"
                with open(index_file, "w", encoding='utf-8') as f:
                    f.write("image_id\tfeat_file\tnum_segments\n")
                    f.write(f"{image_id}\t{image_id}.npz\t{len(data['segment_ids'])}\n")
                
                print(f"   - ç´¢å¼•æ–‡ä»¶: {index_file}")
                
                if not cleanup_temp:
                    print(f"\nğŸ’¾ æ–‡ä»¶å·²ä¿å­˜åˆ°: {temp_dir}")
                    print(f"æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç åŠ è½½æ•°æ®:")
                    print(f"```python")
                    print(f"import numpy as np")
                    print(f"data = np.load('{npz_file}')")
                    print(f"segment_ids = data['segment_ids']")
                    print(f"embeddings = data['embeddings']")
                    print(f"labels = data['labels']")
                    print(f"```")
                
                result = True
            else:
                print("âŒ ä¿å­˜åµŒå…¥å‘é‡å¤±è´¥")
                result = False
        else:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„å›¾åƒå¼ é‡")
            result = False
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if cleanup_temp:
            shutil.rmtree(temp_dir)
        
        return result
        
    except Exception as e:
        print(f"âŒ çœŸå®æ•°æ®é›†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_prep_mask_image():
    """æµ‹è¯•maskå›¾åƒé¢„å¤„ç†åŠŸèƒ½"""
    print("\nğŸ”„ æµ‹è¯•maskå›¾åƒé¢„å¤„ç†...")
    
    try:
        image, masks, labels, target_ids = create_dummy_image_data()
        
        processed_images, valid_indices, valid_segment_ids, valid_labels = prep_mask_image(
            image, masks, labels, target_ids,
            bg_alpha=0.3, pad_ratio=0.1
        )
        
        # éªŒè¯è¿”å›ç»“æœ
        assert len(processed_images) == len(valid_indices) == len(valid_segment_ids) == len(valid_labels)
        assert len(processed_images) <= len(masks)  # å¯èƒ½æœ‰äº›maskæ— æ•ˆ
        
        # æ£€æŸ¥è¿”å›çš„PILå›¾åƒ
        for img in processed_images:
            assert isinstance(img, Image.Image)
            assert img.mode == 'RGB'
        
        # æ£€æŸ¥segment IDså’Œlabels
        for seg_id, label in zip(valid_segment_ids, valid_labels):
            assert isinstance(seg_id, int)
            assert isinstance(label, int)
        
        print(f"âœ… maské¢„å¤„ç†æˆåŠŸï¼Œå¤„ç†äº† {len(processed_images)} ä¸ªæœ‰æ•ˆmask")
        return True
        
    except Exception as e:
        print(f"âŒ maské¢„å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_save_image_embeddings():
    """æµ‹è¯•å›¾åƒåµŒå…¥ä¿å­˜åŠŸèƒ½"""
    print("\nğŸ”„ æµ‹è¯•å›¾åƒåµŒå…¥ä¿å­˜...")
    
    try:
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = Path(tempfile.mkdtemp())
        
        # åˆ›å»ºè™šæ‹ŸåµŒå…¥æ•°æ®
        image_id = "test_image_001"
        segment_ids = [12345, 67890, 11111]
        labels = [1, 2, 3]
        
        # åˆ›å»ºè™šæ‹Ÿçš„768ç»´åµŒå…¥å‘é‡å¼ é‡ï¼ˆæ›´ç¬¦åˆå®é™…SigLIPè¾“å‡ºï¼‰
        embeddings = torch.randn(3, 768)  # æ‰¹é‡å½¢å¼çš„å¼ é‡
        
        # ä¿å­˜åµŒå…¥
        success = save_image_embeddings(temp_dir, image_id, segment_ids, embeddings, labels)
        assert success, "ä¿å­˜å¤±è´¥"
        
        # éªŒè¯æ–‡ä»¶æ˜¯å¦åˆ›å»º
        npz_file = temp_dir / f"{image_id}.npz"
        assert npz_file.exists(), "NPZæ–‡ä»¶æœªåˆ›å»º"
        
        # åŠ è½½å¹¶éªŒè¯æ•°æ®
        data = np.load(npz_file)
        
        # æ£€æŸ¥é”®æ˜¯å¦å­˜åœ¨
        assert 'segment_ids' in data
        assert 'embeddings' in data
        assert 'labels' in data
        
        # æ£€æŸ¥æ•°æ®å½¢çŠ¶å’Œå†…å®¹
        loaded_segment_ids = data['segment_ids']
        loaded_embeddings = data['embeddings']
        loaded_labels = data['labels']
        
        assert loaded_segment_ids.shape == (3,)
        assert loaded_embeddings.shape == (3, 768)  # 768ç»´SigLIPåµŒå…¥
        assert loaded_labels.shape == (3,)
        
        assert loaded_embeddings.dtype == np.float16  # æ£€æŸ¥fp16æ ¼å¼
        
        # æ£€æŸ¥æ•°æ®å†…å®¹
        np.testing.assert_array_equal(loaded_segment_ids, segment_ids)
        np.testing.assert_array_equal(loaded_labels, labels)
        
        # éªŒè¯åµŒå…¥å‘é‡çš„æ•°å€¼èŒƒå›´åˆç†
        assert not np.isnan(loaded_embeddings).any(), "åµŒå…¥å‘é‡åŒ…å«NaNå€¼"
        assert np.isfinite(loaded_embeddings).all(), "åµŒå…¥å‘é‡åŒ…å«æ— ç©·å¤§å€¼"
        
        print(f"âœ… å›¾åƒåµŒå…¥ä¿å­˜æˆåŠŸ")
        print(f"   - æ–‡ä»¶: {npz_file}")
        print(f"   - Segmentæ•°é‡: {len(segment_ids)}")
        print(f"   - åµŒå…¥ç»´åº¦: {loaded_embeddings.shape}")
        print(f"   - æ•°æ®ç±»å‹: {loaded_embeddings.dtype}")
        print(f"   - åµŒå…¥èŒƒå›´: [{loaded_embeddings.min():.3f}, {loaded_embeddings.max():.3f}]")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        shutil.rmtree(temp_dir)
        
        return True
        
    except Exception as e:
        print(f"âŒ å›¾åƒåµŒå…¥ä¿å­˜å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_dataloader():
    """æµ‹è¯•æ•°æ®åŠ è½½å™¨åˆ›å»º"""
    print("\nğŸ”„ æµ‹è¯•æ•°æ®åŠ è½½å™¨åˆ›å»º...")
    
    # ä½¿ç”¨é»˜è®¤å‚æ•°åˆ›å»ºä¸€ä¸ªå°çš„æµ‹è¯•æ•°æ®åŠ è½½å™¨
    try:
        dataloader = create_dataloader(
            data_path="/home/host_ssd/coconut_dataset/coco",  # ä¸´æ—¶è·¯å¾„ï¼Œä¸ä¼šçœŸæ­£åŠ è½½æ•°æ®
            batch_size=2,
            num_workers=0  # é¿å…å¤šè¿›ç¨‹é—®é¢˜
        )
        print("âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å™¨åˆ›å»ºå¤±è´¥: {e}")
        return False


def test_embedder():
    """æµ‹è¯•SigLIPåµŒå…¥å™¨åˆ›å»º"""
    print("\nğŸ”„ æµ‹è¯•SigLIPåµŒå…¥å™¨åˆ›å»º...")
    
    if not NOVIC_AVAILABLE:
        print("âš ï¸ è·³è¿‡åµŒå…¥å™¨æµ‹è¯•ï¼ˆnovicä¸å¯ç”¨ï¼‰")
        return True
    
    try:
        import os
        os.environ['HF_HOME'] = '/home/host_ssd/huggingface'
        os.environ['TRANSFORMERS_CACHE'] = '/home/host_ssd/huggingface'
        embedder = Embedder.create(
            spec="openclip:ViT-B-16-SigLIP",
            # spec = "/home/host_ssd/huggingface/ViT-B-16-SigLIP",
            device="cuda",  # 
            load_model=False,  # ä¸å®é™…åŠ è½½æ¨¡å‹æƒé‡
        )
        print("âœ… SigLIPåµŒå…¥å™¨åˆ›å»ºæˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ SigLIPåµŒå…¥å™¨åˆ›å»ºå¤±è´¥: {e}")
        return False


def test_npz_file_format():
    """æµ‹è¯•NPZæ–‡ä»¶æ ¼å¼çš„å®Œæ•´æ€§"""
    print("\nğŸ”„ æµ‹è¯•NPZæ–‡ä»¶æ ¼å¼...")
    
    try:
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = Path(tempfile.mkdtemp())
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        image_id = "format_test_001"
        segment_ids = [1001, 2002, 3003, 4004]
        labels = [10, 20, 30, 40]
        embeddings = [torch.randn(512) for _ in range(4)]
        
        # ä¿å­˜æ•°æ®
        save_image_embeddings(temp_dir, image_id, segment_ids, embeddings, labels)
        
        # åŠ è½½æ•°æ®å¹¶è¿›è¡Œè¯¦ç»†éªŒè¯
        npz_file = temp_dir / f"{image_id}.npz"
        data = np.load(npz_file)
        
        # éªŒè¯æ•°æ®ä¸€è‡´æ€§
        assert len(data['segment_ids']) == len(data['embeddings']) == len(data['labels'])
        
        # éªŒè¯æ¯ä¸ªsegmentçš„åµŒå…¥å‘é‡éƒ½æ˜¯512ç»´
        for i, embedding in enumerate(data['embeddings']):
            assert embedding.shape == (512,), f"ç¬¬{i}ä¸ªåµŒå…¥å‘é‡ç»´åº¦é”™è¯¯"
            assert not np.isnan(embedding).any(), f"ç¬¬{i}ä¸ªåµŒå…¥å‘é‡åŒ…å«NaN"
        
        # éªŒè¯segment_idsçš„å”¯ä¸€æ€§
        unique_ids = np.unique(data['segment_ids'])
        assert len(unique_ids) == len(data['segment_ids']), "segment_idsä¸å”¯ä¸€"
        
        print(f"âœ… NPZæ–‡ä»¶æ ¼å¼éªŒè¯é€šè¿‡")
        print(f"   - Segments: {len(data['segment_ids'])}")
        print(f"   - åµŒå…¥å½¢çŠ¶: {data['embeddings'].shape}")
        print(f"   - æ•°æ®ç±»å‹: segment_ids={data['segment_ids'].dtype}, "
              f"embeddings={data['embeddings'].dtype}, labels={data['labels'].dtype}")
        
        # æ¸…ç†
        shutil.rmtree(temp_dir)
        return True
        
    except Exception as e:
        print(f"âŒ NPZæ–‡ä»¶æ ¼å¼æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_edge_cases():
    """æµ‹è¯•è¾¹ç•Œæƒ…å†µ"""
    print("\nğŸ”„ æµ‹è¯•è¾¹ç•Œæƒ…å†µ...")
    
    try:
        # æµ‹è¯•ç©ºæ•°æ®
        temp_dir = Path(tempfile.mkdtemp())
        
        # æµ‹è¯•ç©ºsegment_ids
        result = save_image_embeddings(temp_dir, "empty_test", [], [], [])
        assert not result, "ç©ºæ•°æ®åº”è¯¥è¿”å›False"
        
        # æµ‹è¯•å•ä¸ªsegment
        single_embedding = [torch.randn(512)]
        single_segment_id = [99999]
        single_label = [42]
        
        result = save_image_embeddings(temp_dir, "single_test", single_segment_id, single_embedding, single_label)
        assert result, "å•ä¸ªsegmentä¿å­˜å¤±è´¥"
        
        # éªŒè¯å•ä¸ªsegmentæ–‡ä»¶
        data = np.load(temp_dir / "single_test.npz")
        assert data['segment_ids'].shape == (1,)
        assert data['embeddings'].shape == (1, 512)
        assert data['labels'].shape == (1,)
        
        print("âœ… è¾¹ç•Œæƒ…å†µæµ‹è¯•é€šè¿‡")
        
        # æ¸…ç†
        shutil.rmtree(temp_dir)
        return True
        
    except Exception as e:
        print(f"âŒ è¾¹ç•Œæƒ…å†µæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="æµ‹è¯•build_vis_cacheåŠŸèƒ½")
    parser.add_argument("--data_path", 
                       default="/home/host_ssd/coconut_dataset/coco",
                       help="COCOæ•°æ®é›†è·¯å¾„")
    parser.add_argument("--output_dir",
                       help="æµ‹è¯•è¾“å‡ºç›®å½•ï¼ˆä¸æŒ‡å®šåˆ™ä½¿ç”¨ä¸´æ—¶ç›®å½•ï¼‰")
    parser.add_argument("--skip_real_data", 
                       action="store_true",
                       help="è·³è¿‡çœŸå®æ•°æ®é›†æµ‹è¯•")
    return parser.parse_args()


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    args = parse_args()
    
    print("ğŸ§ª å¼€å§‹æµ‹è¯•build_vis_cacheåŠŸèƒ½...")
    
    # åŸºç¡€æµ‹è¯•
    basic_tests = [
        ("maskå›¾åƒé¢„å¤„ç†", test_prep_mask_image),
        ("å›¾åƒåµŒå…¥ä¿å­˜", test_save_image_embeddings),
        ("NPZæ–‡ä»¶æ ¼å¼", test_npz_file_format),
        ("è¾¹ç•Œæƒ…å†µ", test_edge_cases),
        ("æ•°æ®åŠ è½½å™¨", test_dataloader),
        ("SigLIPåµŒå…¥å™¨", test_embedder),
    ]
    
    results = {}
    for test_name, test_func in basic_tests:
        results[test_name] = test_func()
    
    # çœŸå®æ•°æ®é›†æµ‹è¯•
    if not args.skip_real_data:
        print(f"\n{'='*60}")
        print("ğŸ¯ å¼€å§‹çœŸå®æ•°æ®é›†æµ‹è¯•...")
        print(f"{'='*60}")
        
        real_data_result = test_real_dataset(args.data_path, args.output_dir)
        results["çœŸå®æ•°æ®é›†å¤„ç†"] = real_data_result
    else:
        print("\nâš ï¸ è·³è¿‡çœŸå®æ•°æ®é›†æµ‹è¯•")
    
    # æ€»ç»“æµ‹è¯•ç»“æœ
    print(f"\n{'='*60}")
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    print(f"{'='*60}")
    
    passed = 0
    total = len(results)
    
    for test_name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name:20} : {status}")
        if result:
            passed += 1
    
    print("=" * 60)
    print(f"æ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("\nğŸ’¡ build_vis_cacheåŠŸèƒ½ç‰¹ç‚¹:")
        print("   âœ… ä»¥å›¾åƒä¸ºå•ä½ä¿å­˜segment embeddings")
        print("   âœ… NPZæ ¼å¼ï¼ŒåŒ…å«segment_idsã€embeddingsã€labels")
        print("   âœ… fp16ç²¾åº¦å­˜å‚¨ï¼ŒèŠ‚çœç©ºé—´")
        print("   âœ… å‹ç¼©å­˜å‚¨æ ¼å¼")
        print("   âœ… çœŸå®COCOæ•°æ®é›†éªŒè¯é€šè¿‡")
        print("\nğŸš€ æ‚¨ç°åœ¨å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥æ„å»ºå®Œæ•´çš„è§†è§‰åµŒå…¥ç¼“å­˜:")
        print("   cd eomt")
        print("   python datasets/build_vis_cache.py --data_path /path/to/coco/dataset")
    else:
        print(f"\nâš ï¸  {total-passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°")
        
    return passed == total


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 