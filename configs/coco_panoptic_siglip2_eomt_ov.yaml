MODEL:
  BACKBONE:
    NAME: ViT-B-16-SigLIP2-512
    MODEL_ID: "/home/host/siglip2/"
    DROP_PATH: 0.1
    NAFLEX: false
    FREEZE: false
    FP16: false
    LORA:
      ENABLED: true
      LAST_N_LAYERS: 12
      RANK_ATTN: 16
      RANK_FFN: 32
      ALPHA_SCALE: 2.0
      DROPOUT: 0.05
      BIAS: "none"
  HEAD:
    TYPE: EoMT
    NUM_QUERIES: 150
    NUM_BLOCKS: 4
    MASK_PROJ_DIM: ${MODEL.BACKBONE.EMBED_DIM}
    QUERY_INIT: "text+learnable"
  OPEN_VOCAB:
    ENABLED: true
    TEXT_MODEL_ID: "/home/host/siglip2/"
    MULTILINGUAL: false
    TEMP: 0.02
    CALIBRATION_BIAS: 0.0
    ENERGY_REJECT_THR: -inf
    SYNONYMS_JSON: null
LOSS:
  MATCH:
    LAMBDA_MASK_IOU: 2.0
    LAMBDA_BCE: 2.0
    LAMBDA_CLS: 1.0
  OV:
    KL_TEXT_WEIGHT: 0.5
  DISTILL:
    FEAT_ALIGN: 0.001
    ITC_WEIGHT: 0.05
  SEG:
    FOCAL_GAMMA: 2.0
    FOCAL_ALPHA: 0.25
    DICE_EPS: 1.0e-5
ANNEAL:
  ENABLED: true
  L2_BLOCKS: 4
  SCHEDULE: "poly"
  FACTOR: 0.9
  START_P: 1.0
  END_P: 0.0
DATA:
  DATASET: coco_panoptic
  ROOT: "/home/host/coco"
  TRAIN_SPLIT: train2017
  VAL_SPLIT: val2017
  TRAIN_RES_MIN: 512
  TRAIN_RES_MAX: 512
  BATCH_SIZE: 4
  NUM_WORKERS: 8
  OPEN_VOCAB_SPLIT: "ovp_val"
SOLVER:
  OPTIM: AdamW
  WD: 0.05
  LR_HEAD: 5.0e-4
  LR_LORA: 1.0e-4
  LLRD: 0.8
  CLIP_GRAD: 1.0
  EPOCHS: 12
  LR_SCHEDULE: "poly"
  LR_DECAY_FACTOR: 0.9
  WARMUP_STEPS: [500, 1000]
TEST:
  EVAL_PQ: true
  MIN_MASK_SCORE: 0.5
  MIN_AREA: 256
  OV_LOGIT_BIAS: 0.0
OUTPUT_DIR: "<OUTPUT_DIR>"

TRAINER:
  PRECISION: "32"